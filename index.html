<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>davideabati.info</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Davide Abati</name>
              </p>
			   <p>
                I am a senior engineer at <a href="https://www.qualcomm.com/invention/artificial-intelligence/ai-research">Qualcomm AI Research</a>,  working on deep learning for efficient video processing.
              </p>
              <p>I got my Ph.D. at <a href="http://imagelab.ing.unimore.it/imagelab/index.asp">AimageLab</a>, at the University of Modena and Reggio Emilia, in Italy. I worked under the supervision of <a href="http://imagelab.ing.unimore.it/imagelab/person.asp?idpersona=1">Prof. Rita Cucchiara</a>.
              </p>
 
              <p style="text-align:center">
                <a href="mailto:davideabati@outlook.com">Email</a> &nbsp/&nbsp
                <a href="data/DavideAbati-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=D9UXjKgAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/DavideA">Github</a> &nbsp/&nbsp
                <a href="https://twitter.com/davideabati">Twitter</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/davideabati/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="images/DavideAbati.jpeg" class="hoverZoomLink"/>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
			  The first part of my Ph.D. has been devoted to computer vision for automotive applications. I then developed a strong interest in deep generative models, and their application in out-of-distribution detection and continual learning. More recently, I have been working on efficient video processing.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				<tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='glsa_image'><img src='images/glsa.PNG'></div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.bmvc2021-virtualconference.com/assets/papers/1240.pdf">
                <papertitle>Efficient Video Super Resolution by Gated Local Self Attention</papertitle>
              </a>
              <br>
			  <strong>Davide Abati</strong>,
			  <a href="https://aghodrati.github.io/">Amir Ghodrati</a>,
			  <a href="https://habibian.github.io/">Amirhossein Habibian</a>
              <br>
              <em>BMVC</em>, 2021
		<br>
              <a href="data/glsa.bib" target="_blank">bibtex</a>
			  <br>
              <p></p>
              <p>An efficient frame alignment operator for Video Super Resolution based on local self attention. Alignment is carried out only at specific locations as specified by a learnable gating function.</p>
            </td>
          </tr>
		<tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='skip_conv_image'><img src='images/skipconv.PNG'></div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/CVPR2021/html/Habibian_Skip-Convolutions_for_Efficient_Video_Processing_CVPR_2021_paper.html">
                <papertitle>Skip-Convolutions for Efficient Video Processing</papertitle>
              </a>
              <br>
			  <a href="https://habibian.github.io/">Amirhossein Habibian</a>,
              <strong>Davide Abati</strong>,
			  <a href="https://tacocohen.wordpress.com/">Taco Cohen</a>,			  
			  <a href="http://babakint.com/">Babak Ehteshami Bejnordi</a>
              <br>
              <em>CVPR</em>, 2021
		<br>
              <a href="https://arxiv.org/abs/2104.11487">arXiv</a> &nbsp/&nbsp
              <a href="data/skipconv.bib" target="_blank">bibtex</a> &nbsp/&nbsp
			  <a href="https://github.com/Qualcomm-AI-research/Skip-Conv" target="_blank">code</a>
			  <br>
              <p></p>
              <p>By selectively applying convolutions only on locations that carry meaningful information, the computational cost of neural networks on video can be reduced by 4~5 times.</p>
            </td>
          </tr>
		<tr onmouseout="der_stop()" onmouseover="der_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
			                  <img class="two" src='images/der.jpg'>

                <div class="two" id='der_image'><img src='images/der.gif'></div>
              </div>
              <script type="text/javascript">
                function der_start() {
                  document.getElementById('der_image').style.opacity = "1";
                }

                function der_stop() {
                  document.getElementById('der_image').style.opacity = "0";
                }
                der_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://papers.nips.cc/paper/2020/hash/b704ea2c39778f07c617f6b7ce480e9e-Abstract.html">
                <papertitle>Dark Experience for General Continual Learning: a Strong, Simple Baseline</papertitle>
              </a>
              <br>
			  Pietro Buzzega,
			  Matteo Boschini,
			  Angelo Porrello,
              <strong>Davide Abati</strong>,
			  Simone Calderara
              <br>
              <em>NeurIPS</em>, 2020
		<br>
              <a href="https://arxiv.org/abs/2004.07211">arXiv</a> &nbsp/&nbsp
              <a href="data/der.bib" target="_blank">bibtex</a> &nbsp/&nbsp
			  <a href="">code</a>
              <br>
              <p></p>
              <p>We tackle general continual learning, where an agent is required to learn multiple tasks in a sequence under minimal assumptions about their nature. 
			     We run an extensive comparison of many existing methods and introduce a simple model based on knowledge distillation outperforming all of them.</p>
            </td>
          </tr>
		<tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='continual_image'><img src='images/continual.jpg'></div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Abati_Conditional_Channel_Gated_Networks_for_Task-Aware_Continual_Learning_CVPR_2020_paper.html">
                <papertitle>Conditional Channel Gated Networks for Task-Aware Continual Learning</papertitle>
              </a>
              <br>
              <strong>Davide Abati</strong>,
	  	<a href="https://jmtomczak.github.io/">Jakub Tomczak</a>,
		    Tijmen Blankevoort,
		    Simone Calderara,
		    Rita Cucchiara,
	  	<a href="http://babakint.com/">Babak Ehteshami Bejnordi</a>
              <br>
              <em>CVPR</em>, 2020 <font color="red"><strong>(Oral presentation)</strong></font>
		<br>
              <a href="https://arxiv.org/abs/2004.00070">arXiv</a> &nbsp/&nbsp
              <a href="data/tacl.bib" target="_blank">bibtex</a> &nbsp/&nbsp
			  <a href="https://www.youtube.com/watch?v=Qp2g-CzlxjQ&ab_channel=ComputerVisionFoundationVideos">talk</a> &nbsp/&nbsp
			  <a href="https://www.youtube.com/watch?v=k0kMx4BFLmI&ab_channel=2d3d.ai">lecture</a>
              <br>
              <p></p>
              <p>A continual learning model based on the framework of conditional computation.</p>
            </td>
          </tr>
		<tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lsa_image'><img src='images/lsa.jpg'></div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_CVPR_2019/html/Abati_Latent_Space_Autoregression_for_Novelty_Detection_CVPR_2019_paper.html">
                <papertitle>Latent Space Autoregression for Novelty Detection</papertitle>
              </a>
              <br>
              <strong>Davide Abati</strong>,
			  Angelo Porrello,
			  Simone Calderara,
			  Rita Cucchiara
              <br>
              <em>CVPR</em>, 2019
              <br>
              <a href="https://arxiv.org/abs/1807.01653">arXiv</a> &nbsp/&nbsp
              <a href="https://github.com/aimagelab/novelty-detection">code</a> &nbsp/&nbsp
              <a href="data/lsa_poster.pdf">poster</a> &nbsp/&nbsp
			  <a href="data/lsa.bib" target="_blank">bibtex</a>
              <br>
              <p></p>
              <p>Applying autoregression in an autoencoder's latent space increases its out-of-distribution detection capabilities.</p>
            </td>
          </tr>
		  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ccp_image'><img src='images/ccp.jpg'></div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://proceedings.mlr.press/v89/porrello19a.html">
                <papertitle>Classifying Signals on Irregular Domains via Convolutional Cluster Pooling</papertitle>
              </a>
              <br>
			  Angelo Porrello,
              <strong>Davide Abati</strong>,
			  Simone Calderara,
			  Rita Cucchiara
              <br>
              <em>AISTATS</em>, 2019
              <br>
              <a href="https://arxiv.org/abs/1902.04850">arXiv</a> &nbsp/&nbsp
              <a href="data/ccp_poster.pdf">poster</a> &nbsp/&nbsp
			  <a href="data/ccp.bib" target="_blank">bibtex</a>
              <br>
              <p></p>
              <p>We propose a local graph operator resembling convolution as applied in modern neural nets. 
			  Can be applied on skeletons, documents, images.</p>
            </td>
          </tr>
		  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ssof_image'><img src='images/ssof.jpg'></div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://imagelab.ing.unimore.it/imagelab/pubblicazioni/ssof-its2018.pdf">
                <papertitle>Self-Supervised Optical Flow Estimation by Projective Bootstrap</papertitle>
              </a>
              <br>
			  Stefano Alletto,
              <strong>Davide Abati</strong>,
			  Simone Calderara,
			  Rita Cucchiara,
			  Luca Rigazio
              <br>
              <em>IEEE Transactions on Intelligent Transportation Systems</em>, 2018
              <br>
              <a href="https://www.youtube.com/watch?v=3mHd1qbwLNg">video</a> &nbsp/&nbsp
			  <a href="data/ssof.bib" target="_blank">bibtex</a>
              <br>
              <p></p>
              <p>A self-supervised model for optical flow estimation in automotive settings.
			  The flow field is initialized with the prediction of a single projective matrix.
			  </p>
            </td>
          </tr>
		<tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dreyeve_image'><img src='images/dreyeve.jpg'></div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/8375682">
                <papertitle>Predicting the Driver's Focus of Attention: the DR(eye)VE Project</papertitle>
              </a>
              <br>
			  <a href="https://andreapalazzi.info/">Andrea Palazzi</a>,
              <strong>Davide Abati</strong>,
			  Francesco Solera,
			  Simone Calderara,
			  Rita Cucchiara
              <br>
              <em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, 2018
              <br>
              <a href="https://arxiv.org/abs/1705.03854">arXiv</a> &nbsp/&nbsp
			  <a href="http://aimagelab.ing.unimore.it/dreyeve">dataset</a> &nbsp/&nbsp
              <a href="https://github.com/ndrplz/dreyeve">code</a> &nbsp/&nbsp
              <a href="https://www.youtube.com/watch?v=GKjzOcwoc68">video</a> &nbsp/&nbsp
			  <a href="data/dreyeve.bib" target="_blank">bibtex</a>
              <br>
              <p></p>
              <p>We introduce a dataset of human fixations while driving, and a model to predict them given an urban scene.</p>
            </td>
          </tr>
		  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='birdseye_image'><img src='images/birdseye.jpg'></div>
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://link.springer.com/chapter/10.1007/978-3-319-68560-1_21">
                <papertitle>Learning to Map Vehicles into Bird’s Eye View</papertitle>
              </a>
              <br>
			  <a href="https://andreapalazzi.info/">Andrea Palazzi</a>,
			  <a href="http://www.guidoborghi.it/">Guido Borghi</a>,
              <strong>Davide Abati</strong>,
			  Simone Calderara,
			  Rita Cucchiara
              <br>
              <em>International Conference on Image Analysis and Processing</em>, 2017
              <br>
			  <font color="red"><strong>Best paper honorable mention</strong></font>
			  <br>
              <a href="https://arxiv.org/abs/1706.08442">arXiv</a> &nbsp/&nbsp
			  <a href="http://imagelab.ing.unimore.it/imagelab/page.asp?IdPage=19">dataset</a> &nbsp/&nbsp
              <a href="https://github.com/ndrplz/surround_vehicles_awareness">code</a> &nbsp/&nbsp
			  <a href="https://www.youtube.com/watch?v=t2mXv9j6LNw">video</a> &nbsp/&nbsp
			  <a href="data/birdseye.bib" target="_blank">bibtex</a>
              <br>
              <p></p>
              <p>A dataset with matched localization of vehicles from both camera car and birdseye view, created from computer games. And a baseline model for mapping locations across views.</p>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Reviewing Service</heading>
			<p>
			  Journals:
            </p>
			<ul>
				<li><p>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</p></li>
				<li><p>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</p></li>
				<li><p>IEEE Transactions on Multimedia (TMM)</p></li>
				<li><p>IEEE Transactions on Intelligent Transportation Systems (TITS)</p></li>
				<li><p>Neural Networks (NEUNET)</p></li>				
				<li><p>Pattern Recognition Letters (PRL)</p></li>				
			</ul>
			<p>
			  Conferences:
            </p>
			<ul>
				<li><p>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) - Outstanding reviewer 2021</p></li>
				<li><p>IEEE International Conference on Computer Vision (ICCV)</p></li>
				<li><p>Neural Information Processing Systems (NeurIPS)</p></li>
				<li><p>International Conference on Representation Learning (ICLR)</p></li>
				<li><p>International Conference on Machine Learning (ICML)</p></li>
				<li><p>International Joint Conferences on Artificial Intelligence (IJCAI)</p></li>
			</ul>
			</td>
			
		</tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Other</heading>
            <ul>
				<li><p><a href="https://github.com/ndrplz/ConvLSTM_pytorch">ConvLSTM_pytorch</a> (with ndrplz)</p></li>
				<li><p><a href="https://github.com/ndrplz/google-drive-downloader">google-drive-downloader</a> (with ndrplz)</p></li>
				<li><p><a href="https://www.youtube.com/channel/UCGbeqxHxjXUgCk3KS3B64Vw">Sometimes I play guitar</a></p></li>
		</td>
		</tr>
        </tbody></table>
		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <a href="https://jonbarron.info/">I like this website.</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
